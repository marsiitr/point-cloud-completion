{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-21T04:28:58.977554Z",
     "iopub.status.busy": "2024-06-21T04:28:58.977192Z",
     "iopub.status.idle": "2024-06-21T04:29:13.186468Z",
     "shell.execute_reply": "2024-06-21T04:29:13.185664Z",
     "shell.execute_reply.started": "2024-06-21T04:28:58.977523Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-21 04:29:01.304109: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-06-21 04:29:01.304202: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-06-21 04:29:01.478767: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from matplotlib import pyplot as plt\n",
    "tf.random.set_seed(1234)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-21T06:09:32.163370Z",
     "iopub.status.busy": "2024-06-21T06:09:32.163008Z",
     "iopub.status.idle": "2024-06-21T07:03:28.439211Z",
     "shell.execute_reply": "2024-06-21T07:03:28.438288Z",
     "shell.execute_reply.started": "2024-06-21T06:09:32.163342Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/25: 100%|██████████| 906/906 [02:08<00:00,  7.05batch/s, loss=0.0886]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/25], Loss: 0.0886\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/25: 100%|██████████| 906/906 [02:09<00:00,  7.02batch/s, loss=0.064]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/25], Loss: 0.0640\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/25: 100%|██████████| 906/906 [02:09<00:00,  7.00batch/s, loss=0.0607] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/25], Loss: 0.0607\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/25: 100%|██████████| 906/906 [02:09<00:00,  7.00batch/s, loss=0.0589] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/25], Loss: 0.0589\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/25: 100%|██████████| 906/906 [02:09<00:00,  6.99batch/s, loss=0.0574] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/25], Loss: 0.0574\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/25: 100%|██████████| 906/906 [02:09<00:00,  6.99batch/s, loss=0.0563] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/25], Loss: 0.0563\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/25: 100%|██████████| 906/906 [02:09<00:00,  6.99batch/s, loss=0.0554] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/25], Loss: 0.0554\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/25: 100%|██████████| 906/906 [02:09<00:00,  6.99batch/s, loss=0.0547] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/25], Loss: 0.0547\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/25: 100%|██████████| 906/906 [02:09<00:00,  7.00batch/s, loss=0.0538] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/25], Loss: 0.0538\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/25: 100%|██████████| 906/906 [02:09<00:00,  7.00batch/s, loss=0.0533] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/25], Loss: 0.0533\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/25: 100%|██████████| 906/906 [02:09<00:00,  7.00batch/s, loss=0.0528] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [11/25], Loss: 0.0528\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/25: 100%|██████████| 906/906 [02:09<00:00,  6.99batch/s, loss=0.0522] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [12/25], Loss: 0.0522\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13/25: 100%|██████████| 906/906 [02:09<00:00,  7.00batch/s, loss=0.052]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [13/25], Loss: 0.0520\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14/25: 100%|██████████| 906/906 [02:09<00:00,  7.00batch/s, loss=0.0516] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [14/25], Loss: 0.0516\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15/25: 100%|██████████| 906/906 [02:09<00:00,  7.00batch/s, loss=0.0513] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [15/25], Loss: 0.0513\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16/25: 100%|██████████| 906/906 [02:09<00:00,  7.00batch/s, loss=0.0509] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [16/25], Loss: 0.0509\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17/25: 100%|██████████| 906/906 [02:09<00:00,  7.00batch/s, loss=0.0506] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [17/25], Loss: 0.0506\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18/25: 100%|██████████| 906/906 [02:09<00:00,  7.00batch/s, loss=0.0504] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [18/25], Loss: 0.0504\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19/25: 100%|██████████| 906/906 [02:09<00:00,  7.00batch/s, loss=0.0502] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [19/25], Loss: 0.0502\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20/25: 100%|██████████| 906/906 [02:09<00:00,  7.00batch/s, loss=0.0499] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [20/25], Loss: 0.0499\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21/25: 100%|██████████| 906/906 [02:09<00:00,  7.00batch/s, loss=0.0497] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [21/25], Loss: 0.0497\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 22/25: 100%|██████████| 906/906 [02:09<00:00,  7.00batch/s, loss=0.0495] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [22/25], Loss: 0.0495\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 23/25: 100%|██████████| 906/906 [02:09<00:00,  7.00batch/s, loss=0.0494] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [23/25], Loss: 0.0494\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 24/25: 100%|██████████| 906/906 [02:09<00:00,  7.01batch/s, loss=0.0492] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [24/25], Loss: 0.0492\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 25/25: 100%|██████████| 906/906 [02:09<00:00,  7.00batch/s, loss=0.0491] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [25/25], Loss: 0.0491\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Encoder definition\n",
    "class PointNetEncoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(PointNetEncoder, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(3, 64, 1)\n",
    "        self.conv2 = nn.Conv1d(64, 128, 1)\n",
    "        self.conv3 = nn.Conv1d(128, 1024, 1)\n",
    "        self.fc1 = nn.Linear(1024, 512)\n",
    "        self.fc2 = nn.Linear(512, 256)\n",
    "        self.fc3 = nn.Linear(256, 1024)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = torch.max(x, 2)[0]\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "# Decoder definition\n",
    "class PointCloudDecoder(nn.Module):\n",
    "    def __init__(self, num_points):\n",
    "        super(PointCloudDecoder, self).__init__()\n",
    "        self.num_points = num_points\n",
    "        self.fc1 = nn.Linear(1024, 256)\n",
    "        self.fc2 = nn.Linear(256, 512)\n",
    "        self.fc3 = nn.Linear(512, num_points * 3)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        x = x.view(-1, 3, self.num_points)\n",
    "        return x\n",
    "\n",
    "# Model combining encoder and decoder\n",
    "class PointCompletionNet(nn.Module):\n",
    "    def __init__(self, num_points=2048):\n",
    "        super(PointCompletionNet, self).__init__()\n",
    "        self.encoder = PointNetEncoder()\n",
    "        self.decoder = PointCloudDecoder(num_points)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.transpose(1, 2)  # Transpose to (batch_size, 3, num_points)\n",
    "        features = self.encoder(x)\n",
    "        reconstructed = self.decoder(features)\n",
    "        return reconstructed.transpose(1, 2)  # Transpose back to (batch_size, num_points, 3)\n",
    "\n",
    "# Dataset class\n",
    "class PointCloudDataset(Dataset):\n",
    "    def __init__(self, partial_data, gt_data):\n",
    "        self.partial_data = partial_data.astype(np.float32)\n",
    "        self.gt_data = gt_data.astype(np.float32)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.partial_data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        partial = self.partial_data[idx]\n",
    "        gt = self.gt_data[idx]\n",
    "        return partial, gt\n",
    "\n",
    "# Chamfer Distance (simplified version)\n",
    "def chamfer_distance(pred, gt):\n",
    "    batch_size, num_points, _ = pred.size()\n",
    "    pred = pred.unsqueeze(1).repeat(1, num_points, 1, 1)\n",
    "    gt = gt.unsqueeze(2).repeat(1, 1, num_points, 1)\n",
    "    dist = torch.norm(pred - gt, dim=-1)\n",
    "    dist1 = dist.min(dim=2)[0]\n",
    "    dist2 = dist.min(dim=1)[0]\n",
    "    return dist1.mean(dim=1) + dist2.mean(dim=1)\n",
    "\n",
    "# Load your datasets\n",
    "partial_dataset = partial_dataset\n",
    "gt_dataset = gt_dataset\n",
    "\n",
    "# Create DataLoader\n",
    "train_dataset = PointCloudDataset(partial_dataset, gt_dataset)\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "# Hyperparameters and model initialization\n",
    "num_points = 2048\n",
    "model = PointCompletionNet(num_points).cuda()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "epochs = 25\n",
    "\n",
    "# Training loop with progress bar\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "\n",
    "    # Initialize the progress bar\n",
    "    with tqdm(total=len(train_loader), desc=f'Epoch {epoch + 1}/{epochs}', unit='batch') as pbar:\n",
    "        for partial, complete in train_loader:\n",
    "            partial, complete = partial.cuda(), complete.cuda()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            reconstructed = model(partial)\n",
    "            loss = chamfer_distance(reconstructed, complete).mean()\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            pbar.set_postfix(loss=running_loss/len(train_loader))\n",
    "            pbar.update(1)\n",
    "\n",
    "    print(f'Epoch [{epoch+1}/{epochs}], Loss: {running_loss/len(train_loader):.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [],
   "dockerImageVersionId": 30733,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
